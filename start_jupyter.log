[I 22:34:37.423 NotebookApp] Serving notebooks from local directory: /home/matteoc/decaf
[I 22:34:37.423 NotebookApp] The Jupyter Notebook is running at:
[I 22:34:37.423 NotebookApp] http://127.0.0.1:9094/?token=4679357c2bff4b55003d5edb899946e4abc3e7bbf9b7a1b1
[I 22:34:37.423 NotebookApp]  or http://127.0.0.1:9094/?token=4679357c2bff4b55003d5edb899946e4abc3e7bbf9b7a1b1
[I 22:34:37.423 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
[C 22:34:37.458 NotebookApp] 
    
    To access the notebook, open this file in a browser:
        file:///home/matteoc/.local/share/jupyter/runtime/nbserver-18695-open.html
    Or copy and paste one of these URLs:
        http://127.0.0.1:9094/?token=4679357c2bff4b55003d5edb899946e4abc3e7bbf9b7a1b1
     or http://127.0.0.1:9094/?token=4679357c2bff4b55003d5edb899946e4abc3e7bbf9b7a1b1
[I 22:34:46.743 NotebookApp] 302 GET /?token=4679357c2bff4b55003d5edb899946e4abc3e7bbf9b7a1b1 (127.0.0.1) 1.50ms
[I 22:34:56.678 NotebookApp] Kernel started: 420c9cee-a6dc-469c-81c9-815815527739
Ivy Default Cache set to: /home/matteoc/.ivy2/cache
The jars for the packages stored in: /home/matteoc/.ivy2/jars
:: loading settings :: url = jar:file:/opt/spark-distro/spark-2.4.4-bin-x509-arrow-hack/jars/ivy-2.4.0.jar!/org/apache/ivy/core/settings/ivysettings.xml
edu.vanderbilt.accre#laurelin added as a dependency
:: resolving dependencies :: org.apache.spark#spark-submit-parent-7649cc70-e04f-44e9-8ba9-a3f74eab8bb6;1.0
	confs: [default]
	found edu.vanderbilt.accre#laurelin;0.4.2-SNAPSHOT in local-m2-cache
	found com.google.guava#guava;28.0-jre in central
	found com.google.guava#failureaccess;1.0.1 in central
	found com.google.guava#listenablefuture;9999.0-empty-to-avoid-conflict-with-guava in central
	found com.google.code.findbugs#jsr305;3.0.2 in central
	found org.checkerframework#checker-qual;2.8.1 in central
	found com.google.errorprone#error_prone_annotations;2.3.2 in central
	found com.google.j2objc#j2objc-annotations;1.3 in central
	found org.codehaus.mojo#animal-sniffer-annotations;1.17 in central
	found org.tukaani#xz;1.2 in central
	found org.lz4#lz4-java;1.5.1 in central
	found org.apache.logging.log4j#log4j-api;2.11.2 in central
	found org.apache.logging.log4j#log4j-core;2.11.2 in central
:: resolution report :: resolve 1114ms :: artifacts dl 182ms
	:: modules in use:
	com.google.code.findbugs#jsr305;3.0.2 from central in [default]
	com.google.errorprone#error_prone_annotations;2.3.2 from central in [default]
	com.google.guava#failureaccess;1.0.1 from central in [default]
	com.google.guava#guava;28.0-jre from central in [default]
	com.google.guava#listenablefuture;9999.0-empty-to-avoid-conflict-with-guava from central in [default]
	com.google.j2objc#j2objc-annotations;1.3 from central in [default]
	edu.vanderbilt.accre#laurelin;0.4.2-SNAPSHOT from local-m2-cache in [default]
	org.apache.logging.log4j#log4j-api;2.11.2 from central in [default]
	org.apache.logging.log4j#log4j-core;2.11.2 from central in [default]
	org.checkerframework#checker-qual;2.8.1 from central in [default]
	org.codehaus.mojo#animal-sniffer-annotations;1.17 from central in [default]
	org.lz4#lz4-java;1.5.1 from central in [default]
	org.tukaani#xz;1.2 from central in [default]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   13  |   0   |   0   |   0   ||   13  |   0   |
	---------------------------------------------------------------------
:: retrieving :: org.apache.spark#spark-submit-parent-7649cc70-e04f-44e9-8ba9-a3f74eab8bb6
	confs: [default]
	0 artifacts copied, 13 already retrieved (0kB/45ms)
19/12/10 22:35:10 WARN SparkConf: The configuration key 'spark.executor.port' has been deprecated as of Spark 2.0.0 and may be removed in the future. Not used anymore
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
19/12/10 22:35:11 WARN SparkConf: The configuration key 'spark.executor.port' has been deprecated as of Spark 2.0.0 and may be removed in the future. Not used anymore
19/12/10 22:35:11 WARN SparkConf: The configuration key 'spark.executor.port' has been deprecated as of Spark 2.0.0 and may be removed in the future. Not used anymore
19/12/10 22:35:11 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
19/12/10 22:35:12 WARN FairSchedulableBuilder: Fair Scheduler configuration file not found so jobs will be scheduled in FIFO order. To use fair scheduling, configure pools in fairscheduler.xml or set spark.scheduler.allocation.file to a file that contains the configuration.
