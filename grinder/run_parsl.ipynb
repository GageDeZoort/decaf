{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
<<<<<<< HEAD
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/matteoc/decaf/grinder:\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(os.environ['PYTHONPATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
=======
>>>>>>> ba329d422bed64d02809df218174d3a2e0ce4178
   "metadata": {},
   "outputs": [],
   "source": [
    "import parsl\n",
    "import os\n",
    "from parsl.app.app import python_app, bash_app\n",
    "from parsl.configs.local_threads import config\n",
    "\n",
    "from parsl.providers import LocalProvider,CondorProvider,SlurmProvider\n",
    "from parsl.channels import LocalChannel,SSHChannel\n",
    "from parsl.config import Config\n",
    "from parsl.executors import HighThroughputExecutor\n",
    "from parsl.launchers import SrunLauncher\n",
    "\n",
    "from parsl.addresses import address_by_hostname\n",
    "\n",
    "x509_proxy = 'x509up_u%s'%(os.getuid())\n",
    "year = '2018'\n",
    "\n",
    "wrk_init = '''\n",
    "export X509_USER_PROXY=${HOME}/x509up_u45169\n",
    "export X509_CERT_DIR=${HOME}/certs/\n",
    "export XRD_RUNFORKHANDLER=1\n",
    "'''#%(x509_proxy)\n",
    "\n",
    "twoGB = 2048\n",
    "nproc = 48\n",
    "\n",
    "sched_opts = '''\n",
    "#SBATCH --cpus-per-task=%d\n",
    "#SBATCH --mem-per-cpu=%d\n",
    "''' % (nproc, twoGB, ) \n",
    "\n",
    "slurm_htex = Config(\n",
    "    executors=[\n",
    "        HighThroughputExecutor(\n",
    "            label=\"coffea_parsl_slurm\",\n",
    "            address=address_by_hostname(),\n",
    "            prefetch_capacity=0,  \n",
    "            max_workers=nproc,\n",
    "            provider=SlurmProvider(\n",
    "                channel=LocalChannel(),\n",
    "                launcher=SrunLauncher(),\n",
    "                init_blocks=72,\n",
    "                max_blocks=72,\n",
    "                nodes_per_block=1,\n",
    "                partition='general',\n",
    "                scheduler_options=sched_opts,   # Enter scheduler_options if needed\n",
    "                worker_init=wrk_init,         # Enter worker_init if needed\n",
    "                walltime='02:00:00'\n",
    "            ),\n",
    "        )\n",
    "    ],\n",
    "    retries=10,\n",
    "    strategy=None,\n",
    ")\n",
    "\n",
    "#parsl.set_stream_logger() # <-- log everything to stdout\n",
    "\n",
    "dfk = parsl.load(slurm_htex)\n",
    "\n",
    "chunksize=500000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lumis = {}\n",
    "#Values from https://twiki.cern.ch/twiki/bin/viewauth/CMS/PdmVAnalysisSummaryTable\n",
    "lumis['2016']=35.92\n",
    "lumis['2017']=41.53\n",
    "lumis['2018']=59.97\n",
    "lumi = 1000.*float(lumis[year])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = {\n",
    "    \"iszeroL\":('ZJets','WJets','DY','TT','ST','WW','WZ','ZZ','QCD','HToBB','MET'),\n",
    "    \"isoneM\":('WJets','DY','TT','ST','WW','WZ','ZZ','QCD','HToBB','MET'),\n",
    "    \"isoneE\":('WJets','DY','TT','ST','WW','WZ','ZZ','QCD','HToBB','SingleElectron','EGamma'),\n",
    "    \"istwoM\":('WJets','DY','TT','ST','WW','WZ','ZZ','HToBB','MET'),\n",
    "    \"istwoE\":('WJets','DY','TT','ST','WW','WZ','ZZ','HToBB','SingleElectron','EGamma'),\n",
    "    \"isoneA\":('GJets','QCD','SinglePhoton','EGamma')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MET____0_': -1, 'EGamma____0_': -1, 'ZJetsToNuNu_HT-100To200_13TeV-madgraph____0_': 280.5, 'ZJetsToNuNu_HT-200To400_13TeV-madgraph____0_': 77.7, 'ZJetsToNuNu_HT-400To600_13TeV-madgraph____0_': 10.71, 'ZJetsToNuNu_HT-600To800_13TeV-madgraph____0_': 2.562, 'ZJetsToNuNu_HT-800To1200_13TeV-madgraph____0_': 1.183, 'ZJetsToNuNu_HT-1200To2500_13TeV-madgraph____0_': 0.286, 'ZJetsToNuNu_HT-2500ToInf_13TeV-madgraph____0_': 0.006945, 'DYJetsToLL_M-50_HT-100to200_TuneCP5_PSweights_13TeV-madgraphMLM-pythia8____0_': 147.4, 'DYJetsToLL_M-50_HT-200to400_TuneCP5_PSweights_13TeV-madgraphMLM-pythia8____0_': 40.99, 'DYJetsToLL_M-50_HT-400to600_TuneCP5_PSweights_13TeV-madgraphMLM-pythia8____0_': 5.678, 'DYJetsToLL_M-50_HT-600to800_TuneCP5_PSweights_13TeV-madgraphMLM-pythia8____0_': 1.367, 'DYJetsToLL_M-50_HT-800to1200_TuneCP5_PSweights_13TeV-madgraphMLM-pythia8____0_': 0.6304, 'DYJetsToLL_M-50_HT-1200to2500_TuneCP5_PSweights_13TeV-madgraphMLM-pythia8____0_': 0.1514, 'DYJetsToLL_M-50_HT-2500toInf_TuneCP5_PSweights_13TeV-madgraphMLM-pythia8____0_': 0.003565, 'WJetsToLNu_HT-100To200_TuneCP5_13TeV-madgraphMLM-pythia8____0_': 1343, 'WJetsToLNu_HT-200To400_TuneCP5_13TeV-madgraphMLM-pythia8____0_': 359.6, 'WJetsToLNu_HT-400To600_TuneCP5_13TeV-madgraphMLM-pythia8____0_': 48.85, 'WJetsToLNu_HT-600To800_TuneCP5_13TeV-madgraphMLM-pythia8____0_': 12.05, 'WJetsToLNu_HT-800To1200_TuneCP5_13TeV-madgraphMLM-pythia8____0_': 5.501, 'WJetsToLNu_HT-1200To2500_TuneCP5_13TeV-madgraphMLM-pythia8____0_': 1.329, 'WJetsToLNu_HT-2500ToInf_TuneCP5_13TeV-madgraphMLM-pythia8____0_': 0.03216, 'GJets_HT-100To200_TuneCP5_13TeV-madgraphMLM-pythia8____0_': 9235, 'GJets_HT-200To400_TuneCP5_13TeV-madgraphMLM-pythia8____0_': 2298, 'GJets_HT-400To600_TuneCP5_13TeV-madgraphMLM-pythia8____0_': 277.6, 'GJets_HT-600ToInf_TuneCP5_13TeV-madgraphMLM-pythia8____0_': 93.47, 'QCD_HT100to200_TuneCP5_13TeV-madgraphMLM-pythia8____0_': 27990000, 'QCD_HT200to300_TuneCP5_13TeV-madgraphMLM-pythia8____0_': 1735000, 'QCD_HT300to500_TuneCP5_13TeV-madgraphMLM-pythia8____0_': 366800, 'QCD_HT500to700_TuneCP5_13TeV-madgraphMLM-pythia8____0_': 29370, 'QCD_HT700to1000_TuneCP5_13TeV-madgraphMLM-pythia8____0_': 6524, 'QCD_HT1000to1500_TuneCP5_13TeV-madgraphMLM-pythia8____0_': 1064, 'QCD_HT1500to2000_TuneCP5_13TeV-madgraphMLM-pythia8____0_': 121.5, 'QCD_HT2000toInf_TuneCP5_13TeV-madgraphMLM-pythia8____0_': 25.42, 'ST_tW_antitop_5f_inclusiveDecays_TuneCP5_13TeV-powheg-pythia8____0_': 35.6, 'ST_tW_top_5f_inclusiveDecays_TuneCP5_13TeV-powheg-pythia8____0_': 35.6, 'ST_t-channel_antitop_4f_InclusiveDecays_TuneCP5_13TeV-powheg-madspin-pythia8____0_': 80.95, 'ST_t-channel_top_4f_InclusiveDecays_TuneCP5_13TeV-powheg-madspin-pythia8____0_': 136.02, 'TTJets_TuneCP5_13TeV-amcatnloFXFX-pythia8____0_': 831.76, 'WW_TuneCP5_13TeV-pythia8____0_': 118.7, 'WZ_TuneCP5_13TeV-pythia8____0_': 47.13, 'ZZ_TuneCP5_13TeV-pythia8____0_': 16.523, 'ZH_HToBB_ZToNuNu_M125_13TeV_powheg_pythia8____0_': 0.08912, 'ZH_HToBB_ZToLL_M125_13TeV_powheg_pythia8____0_': 0.04865, 'ggZH_HToBB_ZToNuNu_M125_13TeV_powheg_pythia8____0_': 0.014366, 'ggZH_HToBB_ZToLL_M125_13TeV_powheg_pythia8____0_': 0.007842, 'WminusH_HToBB_WToLNu_M125_13TeV_powheg_pythia8____0_': 0.1, 'WplusH_HToBB_WToLNu_M125_13TeV_powheg_pythia8____0_': 0.159, 'ttHTobb_M125_TuneCP5_13TeV-powheg-pythia8____0_': 0.2946944, 'GluGluHToBB_M125_13TeV_powheg_pythia8____0_': 28.234752, 'VBFHToBB_M-125_13TeV_powheg_pythia8_weightfix____0_': 2.2026368, 'MonoHs_Mzprime_500_Mhs_50_Mchi_150____0_': 0.2934, 'MonoHs_Mzprime_500_Mhs_70_Mchi_150____0_': 0.2565, 'MonoHs_Mzprime_500_Mhs_90_Mchi_150____0_': 0.224, 'MonoJet_Mzprime_500_Mchi_150____0_': 3.044, 'MonoW_Mzprime_500_Mchi_150____0_': 0.03469, 'MonoZ_Mzprime_500_Mchi_150____0_': 0.01093}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(\"../harvester/beans/\"+year+\".json\") as fin:\n",
    "    samplefiles = json.load(fin)\n",
    "xsec = {k: v['xs'] for k,v in samplefiles.items()}\n",
    "\n",
    "print(xsec)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 5,
>>>>>>> ba329d422bed64d02809df218174d3a2e0ce4178
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the analysis worker from the cloudpickle file\n",
    "#import cloudpickle as cpkl\n",
    "#import lz4.frame as lz4f\n",
    "from analysis.darkhiggs import AnalysisProcessor\n",
    "\n",
    "#processor_pkl = 'AnalysisProcessor.cpkl.lz4'\n",
    "#AnalysisProcessor = None\n",
    "#with lz4f.open(processor_pkl, mode=\"rb\") as fin:\n",
    "#    AnalysisProcessor = cpkl.load(fin)\n",
    "print(AnalysisProcessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
<<<<<<< HEAD
   "outputs": [],
=======
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parsl version: 0.8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Preprocessing:   0%|          | 0/5125 [00:00<?, ?files/s]"
     ]
    }
   ],
>>>>>>> ba329d422bed64d02809df218174d3a2e0ce4178
   "source": [
    "import time\n",
    "from coffea import hist, processor\n",
    "from coffea.processor import run_parsl_job\n",
    "from coffea.processor.parsl.parsl_executor import parsl_executor\n",
    "import gzip\n",
    "import pickle\n",
    "import cloudpickle\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "filelist = {}\n",
    "for dataset, info in samplefiles.items():\n",
    "    #if your_wanted_dataset not in dataset: continue\n",
    "    #dataset = dt.strip().split(\"____\")[0]\n",
    "    if not dataset in filelist: filelist[dataset] = []\n",
    "    fileslice = slice(None)\n",
    "    for file in info['files'][fileslice]:\n",
    "        filelist[dataset].append(file)\n",
    "\n",
    "        \n",
    "selections = {}\n",
    "for dataset in filelist:\n",
    "    if not dataset in selections: selections[dataset] = []\n",
    "    for selection,v in samples.items():\n",
    "        for i in range (0,len(v)):\n",
    "            if v[i] not in dataset: continue\n",
    "    fileset = {}\n",
    "    fileset[dataset] = filelist[dataset]\n",
    "    processor_instance=AnalysisProcessor(selected_regions=selections[dataset], year=year, xsec=xsec, lumi=lumi)\n",
    "    tstart = time.time()\n",
    "    output = run_parsl_job(fileset,\n",
    "                           treename='Events',\n",
    "                           processor_instance=processor_instance,\n",
    "                           executor=parsl_executor,\n",
    "                           executor_args={'config':None, 'flatten': False},\n",
    "                           data_flow=dfk,\n",
    "                           chunksize=500000,\n",
    "                          )\n",
    "\n",
    "    # Pickle is not very fast or memory efficient, will be replaced by something better soon\n",
    "    with lz4f.open(\"pods/\"+year+\"/\"+dataset+\".pkl.gz\", mode=\"wb\", compression_level=5) as fout:\n",
    "        cloudpickle.dump(output, fout)\n",
    "        \n",
    "    dt = time.time() - tstart\n",
    "    nbins = sum(sum(arr.size for arr in h._sumw.values()) for h in output.values() if isinstance(h, hist.Hist))\n",
    "    nfilled = sum(sum(np.sum(arr > 0) for arr in h._sumw.values()) for h in output.values() if isinstance(h, hist.Hist))\n",
    "    print(\"Filled %.1fM bins\" % (nbins/1e6, ))\n",
    "    print(\"Nonzero bins: %.1f%%\" % (100*nfilled/nbins, ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsl.dfk().cleanup()\n",
    "parsl.clear()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
